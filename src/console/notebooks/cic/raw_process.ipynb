{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "csv_fname = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_output_if_exists = True \n",
    "\"\"\"Indicates whether to reload any outputs from the Notebook if they already exist.\"\"\"\n",
    "\n",
    "self_classify = False\n",
    "\"\"\"Indicates whether to use the LLM to determine its own classifications for the data, or to use the pre-defined `classifications`.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [\n",
    "    {\n",
    "        \"classification\": \"Integration\",\n",
    "        \"description\": \"Key issues include difficulties integrating capabilities of cloud services into solutions, ensuring seamless interoperability.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Breadth\",\n",
    "        \"description\": \"Key issues include navigating an overwhelming range of service options.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Containers\",\n",
    "        \"description\": \"Key issues include challenges in container orchestration, ensuring compatibility in containerized environments.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Compute\",\n",
    "        \"description\": \"Key issues include optimizing compute resources (e.g., VMs, containers, serverless) for performance and efficient resource utilization.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Ease\",\n",
    "        \"description\": \"Key issues include steep learning curves and inconsistent user experiences with cloud services.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Portal\",\n",
    "        \"description\": \"Key issues include cumbersome navigation, non-intuitive interfaces, and a lack of intuitive design.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"High Cost / Pricing\",\n",
    "        \"description\": \"Key issues include unexpected costs, complex pricing models, and difficulty in predicting costs.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Skill\",\n",
    "        \"description\": \"Key issues include gaps in technical expertise, steep training requirements, and the need for specialized skills.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Customer Support\",\n",
    "        \"description\": \"Key issues include delayed support response times, inconsistent service quality, and limited access to knowledgeable support resources.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Migration\",\n",
    "        \"description\": \"Key issues include navigating the complexities of migrating workloads between cloud providers, from on-premises environments, or hybrid environments.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Privacy\",\n",
    "        \"description\": \"Key issues include data confidentiality concerns, compliance with data protection regulations, and ensuring data security.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Database\",\n",
    "        \"description\": \"Key issues include database performance bottlenecks, data scalability challenges, and managing complex database configurations.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Documentation\",\n",
    "        \"description\": \"Key issues include outdated or incomplete documentation, lack of examples, and difficulty in finding relevant information.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Getting Started\",\n",
    "        \"description\": \"Key issues include overwhelming setup procedures, unclear onboarding processes, and lack of guidance for new users.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"AI\",\n",
    "        \"description\": \"Key issues include integration challenges with AI into existing solutions, ensuring AI models are accurate and efficient, and managing AI workloads.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Missing Features\",\n",
    "        \"description\": \"Key issues include the absence of critical features, limitations in functionality, and gaps in service offerings.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Reliability\",\n",
    "        \"description\": \"Key issues include service outages, inconsistent performance, and lack of redundancy in cloud services.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Innovate\",\n",
    "        \"description\": \"Key issues include slow adoption of cutting-edge technologies, limited support for emerging features, and difficulty integrating new technologies.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Automation\",\n",
    "        \"description\": \"Key issues include complexities in automating cloud services, ensuring automation scripts are reliable, and managing automated workflows.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Scaling\",\n",
    "        \"description\": \"Key issues include challenges in scaling resources to meet demand, optimizing resource allocation, and ensuring performance at scale.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Lock-In\",\n",
    "        \"description\": \"Key issues include dependency on proprietary cloud services, challenges in migrating away from cloud providers, and concerns about vendor lock-in.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Select Service\",\n",
    "        \"description\": \"Key issues include confusion from an abundance of similar services, difficulty in selecting the right service for specific use cases, and lack of clear differentiation between services.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Networking\",\n",
    "        \"description\": \"Key issues include complex network configurations, challenges in optimizing network performance, and managing network security.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"IAM\",\n",
    "        \"description\": \"Key issues include managing intricate identity and access management policies, ensuring secure access controls, and preventing unauthorized access.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Monitor\",\n",
    "        \"description\": \"Key issues include setting up comprehensive observability, integrating effective logging and monitoring solutions, and ensuring timely alerts.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"OS\",\n",
    "        \"description\": \"Key issues include compatibility issues with operating systems, managing OS configurations, and ensuring OS security.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"Multi-Cloud\",\n",
    "        \"description\": \"Key issues include interoperability challenges between cloud providers, managing multiple cloud environments, and ensuring consistent performance across clouds.\"\n",
    "    },\n",
    "    {\n",
    "        \"classification\": \"None\",\n",
    "        \"description\": \"No challenges.\"\n",
    "    }\n",
    "]\n",
    "\"\"\"The classifications to use for the data. If `self_classify` is False, these classifications will be used to classify the data. Otherwise, they will be ignored.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "wdir = os.path.abspath('../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai.types.chat.chat_completion_system_message_param import ChatCompletionSystemMessageParam\n",
    "from openai.types.chat.chat_completion_user_message_param import ChatCompletionUserMessageParam\n",
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = dotenv_values(f\"{wdir}/configuration/.env\")\n",
    "notebooks_path = os.path.join(wdir, \"src/console/notebooks/cic/\")\n",
    "\n",
    "input_dir = os.path.join(notebooks_path, \"input\")\n",
    "csv_fpath = os.path.join(input_dir, csv_fname)\n",
    "output_dir = os.path.join(notebooks_path, \"output\", os.path.splitext(os.path.basename(csv_fname))[0])\n",
    "classifications_output_dir = os.path.join(output_dir, \"self_classifications\" if self_classify else \"classifications\")\n",
    "\n",
    "credential = DefaultAzureCredential(\n",
    "    exclude_workload_identity_credential=True,\n",
    "    exclude_developer_cli_credential=True,\n",
    "    exclude_environment_credential=True,\n",
    "    exclude_managed_identity_credential=True,\n",
    "    exclude_powershell_credential=True,\n",
    "    exclude_shared_token_cache_credential=True,\n",
    "    exclude_interactive_browser_credential=True\n",
    ")\n",
    "\n",
    "openai_token_provider = get_bearer_token_provider(credential, 'https://cognitiveservices.azure.com/.default')\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    azure_endpoint=env_vars[\"AOAI_ENDPOINT\"],\n",
    "    azure_ad_token_provider=openai_token_provider,\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing Helpers\n",
    "class Stopwatch:\n",
    "    elapsed = 0\n",
    "    is_running = False\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.stop()\n",
    "\n",
    "    def reset(self):\n",
    "        self.elapsed = 0\n",
    "        self.is_running = False\n",
    "\n",
    "    def start(self):\n",
    "        if self.is_running:\n",
    "            return\n",
    "\n",
    "        self.is_running = True\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        if not self.is_running:\n",
    "            return\n",
    "\n",
    "        self.is_running = False\n",
    "        self.elapsed = time.perf_counter() - self.start_time\n",
    "\n",
    "    def get_current_elapsed(self):\n",
    "        if not self.is_running:\n",
    "            return self.elapsed\n",
    "\n",
    "        self.elapsed = time.perf_counter() - self.start_time\n",
    "        return self.elapsed\n",
    "\n",
    "\n",
    "# Storage Helpers\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if hasattr(obj, 'to_dict'):\n",
    "            return obj.to_dict()\n",
    "        if hasattr(obj, 'as_dict'):\n",
    "            return obj.as_dict()\n",
    "        if hasattr(obj, 'model_dump'):\n",
    "            return obj.model_dump()\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def create_directory(dir: str, clear_if_not_empty: bool = False) -> str:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    if clear_if_not_empty:\n",
    "        for file in os.listdir(dir):\n",
    "            file_path = os.path.join(dir, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "    return dir\n",
    "\n",
    "\n",
    "def create_json_file(fpath: str, data: any, indent: int = 4) -> None:\n",
    "    if not os.path.exists(os.path.dirname(fpath)):\n",
    "        create_directory(os.path.dirname(fpath))\n",
    "\n",
    "    with open(fpath, 'w') as f:\n",
    "        json.dump(data, f, indent=indent, cls=CustomEncoder)\n",
    "        \n",
    "\n",
    "# OpenAI Helpers\n",
    "def get_embedding(text: str):\n",
    "    embedding_response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=env_vars[\"EMBEDDING_DEPLOYMENTNAME\"]\n",
    "    )\n",
    "    return embedding_response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Classification\n",
    "\n",
    "This prompting technique will use the LLM to determine the key observations/challenges associated with the data point provided. The criteria for determining classifications uses logic regarding common issues and opportunities to improve cloud products/services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_classify_prompt = \"\"\"You are a helpful AI assistant for determining a list of key observations from attributions and verbatims from customers of cloud providers (e.g., Azure, AWS, GCP).\n",
    "The key observations will be used to help program managers, product owners, and engineers understand the most common issues and opportunities for improvement in their products and services.\n",
    "\n",
    "## On your ability to determine key observations\n",
    "\n",
    "- Use the provided customer project data to determine the top key observations, regardless of your own knowledge or information.\n",
    "- Key observations should be specific and detailed to provide the most value.\n",
    "- Ensure the key observations are based on the evidence provided.\n",
    "- Each observation should be unique.\n",
    "- Provide a maximum of 5 key observations.\n",
    "- There is no limit to the number of key observations you can provide.\n",
    "\n",
    "## Key Observation Examples\n",
    "\n",
    "{{\n",
    "  \"short_name\": \"High Cost\",\n",
    "}}\n",
    "\n",
    "{{\n",
    "  \"short_name\": \"Containers\",\n",
    "}}\n",
    "\n",
    "{{\n",
    "  \"short_name\": \"AI\",\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Defined Classification\n",
    "\n",
    "This prompting technique takes a list of pre-defined classification names and descriptions to help the model narrow down the scope of the classification. The output will be based on the most relevant matches to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_prompt = \"\"\"Using the provided classification list, classify the attributions and verbatims from customers of cloud providers (e.g., Azure, AWS, GCP) into one or more of the classifications based on the given facts and data.\n",
    "\n",
    "## On your ability to classify\n",
    "\n",
    "- Use the data provided to classify, regardless of your own knowledge or information.\n",
    "- You must only use the classification list provided.\n",
    "- Ensure the data classifications are based on facts, both quantitative and qualitative.\n",
    "- You must only classify data based on known facts. Do not assume or provide indication that a classification is associated if detail is not provided.\n",
    "- Only return relevant data classifications that you are highly confident of.\n",
    "- Provide a maximum of 5 classifications per data point.\n",
    "- If no classification is applicable, provide an empty list. Ignore classifications that are not applicable.\n",
    "\n",
    "## Classifications\n",
    "\n",
    "{classifications}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Generation\n",
    "\n",
    "To support both classification techniques, this prompting technique will use the model to extract key facts from the provided context, and make logical inferences based on the context to create a fact sheet. This will be used in conjunction with the context to reduce the chances of hallucination, improving the quality of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_prompt = \"\"\"Below I will present you with a user's request, and potential relevant context to help you solve it.\n",
    "\n",
    "Based on the user's request, use the context to answer the following survey to the best of your ability.\n",
    "\n",
    "Here is the user's request:\n",
    "\n",
    "```\n",
    "{task}\n",
    "```\n",
    "\n",
    "Here is the context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Here is the survey:\n",
    "\n",
    "1. List any specific facts or figures that are GIVEN based on the request. It is possible that there are none.\n",
    "2. List any facts that are recalled from memory, your knowledge, or well-reasoned assumptions, etc.\n",
    "\n",
    "When answering this survey, keep in mind that facts will typically be specific details.\n",
    "Provide as many facts as you can, even if they seem trivial or unimportant.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = \"\"\"Context: {context}\n",
    "\n",
    "Facts: {facts}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observation(BaseModel):\n",
    "    short_name: str = Field(description=\"Short name of the key observation/challenge.\")\n",
    "    key_insights: List[str] = Field(\n",
    "        description=\"Detailed list of the key insights that support the observation/challenge, including qualitative and quantitative data.\")\n",
    "    \n",
    "class Observations(BaseModel):\n",
    "    observations: List[Observation] = Field(description=\"List of classifications.\")\n",
    "    \n",
    "class RequestFactsModel(BaseModel):\n",
    "    given_facts: Optional[List[str]] = Field(\n",
    "        description=\"Any specific facts or figures that are GIVEN based on the request. It is possible that there are none.\")\n",
    "    recalled_facts: Optional[List[str]] = Field(\n",
    "        description=\"any facts that are recalled from memory, your knowledge, or well-reasoned assumptions, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pre-Determined Classification] - Generate classification embeddings\n",
    "\n",
    "When adopting the non-self classification technique, in order to determine the similarity of the LLM classifications to the context provided, first generate the embeddings for the classification descriptions.\n",
    "\n",
    "These will be used later for cosine similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reload_output_if_exists and os.path.exists(os.path.join(input_dir, \"classifications.json\")):\n",
    "    classifications = json.load(open(os.path.join(input_dir, \"classifications.json\"), \"r\"))\n",
    "    \n",
    "classifications_updated = False\n",
    "\n",
    "if not self_classify:\n",
    "    for classification in classifications:\n",
    "        if \"embedding\" not in classification:\n",
    "            classification[\"embedding\"] = get_embedding(classification[\"description\"])\n",
    "            classifications_updated = True\n",
    "\n",
    "if classifications_updated:\n",
    "    create_json_file(os.path.join(input_dir, \"classifications.json\"), classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous data\n",
    "\n",
    "To reduce reliance on consistently loading data out of an input CSV file, the data stored as JSON in the output directory is loaded back into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "if reload_output_if_exists and os.path.exists(os.path.join(output_dir)):\n",
    "    for f in os.listdir(output_dir):\n",
    "        if f.endswith(\".json\"):\n",
    "            with open(os.path.join(output_dir, f), 'r') as file:\n",
    "                data.append(json.load(file))\n",
    "                \n",
    "print(f\"Loaded {len(data)} existing data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous data classifications\n",
    "\n",
    "Similarly, the classifications for each data point are loaded back into the notebook so not to process them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dp_observations = []\n",
    "processed_response_ids = []\n",
    "\n",
    "if reload_output_if_exists and os.path.exists(classifications_output_dir):\n",
    "    for f in os.listdir(classifications_output_dir):\n",
    "        if f.endswith(\".json\"):\n",
    "            with open(os.path.join(classifications_output_dir, f), \"r\") as file:\n",
    "                dp_observations = json.load(file)\n",
    "                all_dp_observations.extend(dp_observations)\n",
    "                processed_response_ids.append(f.split(\".\")[0])\n",
    "                \n",
    "print(f\"Loaded {len(all_dp_observations)} existing data point classifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data points from CSV\n",
    "\n",
    "For any data points not yet processed, we load from the CSV file. \n",
    "\n",
    "The `skip_chunks` variable is used to control which data points to load for processing. This is for testing purposes only to not process 1,000s of data points.\n",
    "\n",
    "An embedding is created for each data point which will be later used to determine the similarity to the classification embeddings.\n",
    "\n",
    "The data points are then saved out to the output directory as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chunk_iterator = pd.read_csv(csv_fpath, chunksize=10)\n",
    "    \n",
    "    skip_chunks = 0\n",
    "    for _ in range(skip_chunks):\n",
    "        next(chunk_iterator, None)\n",
    "        \n",
    "    df = next(chunk_iterator, None)\n",
    "    if df is not None:\n",
    "        for j, row in df.iterrows():\n",
    "            if row[\"ResponseId\"] in processed_response_ids or row[\"ResponseId\"] in [dp[\"response_id\"] for dp in data]:\n",
    "                continue\n",
    "            \n",
    "            attribution = [\n",
    "                row[\"BrandAssigned\"],\n",
    "                row[\"SAM11\"],\n",
    "                row[\"TAXALN\"],\n",
    "                \"Other\" if row[\"Q005\"].startswith(\"Other\") else row[\"Q005\"],\n",
    "                row[\"Q005_996_TEXT\"] if row[\"Q005\"].startswith(\"Other\") else \"\",\n",
    "                row[\"Q009_\"],\n",
    "                row[\"Cloud_Usage\"],\n",
    "                row[\"Q082\"],\n",
    "                row[\"Q048b\"],\n",
    "                \"\" if row[\"Q089a_2\"] == \"#NULL!\" else \"ISV\",\n",
    "                \"\" if (row[\"Q102a\"] == \"No\" or row[\"Q102a\"] == \"#NULL!\") else \"Startup\"\n",
    "            ]\n",
    "            \n",
    "            dp = {\n",
    "                \"response_id\": row[\"ResponseId\"],\n",
    "                \"attribution\": \", \".join(attribution),\n",
    "                \"verbatim\": str(row[\"Q024b\"]),\n",
    "            }\n",
    "            \n",
    "            dp[\"embedding\"] = get_embedding(dp[\"verbatim\"])\n",
    "            data.append(dp)\n",
    "            \n",
    "            create_json_file(os.path.join(output_dir, f\"{dp['response_id']}.json\"), dp)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = [d for d in data if d[\"response_id\"] not in processed_response_ids]\n",
    "\n",
    "print(f\"Determined {len(filtered_data)} new data points for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification via LLM\n",
    "\n",
    "For each data point, the LLM is used to determine the key observations/challenges associated with it.\n",
    "\n",
    "First, the fact sheet is generated for the data point.\n",
    "\n",
    "Next, the fact sheet and context are concatenated and passed to the LLM for classification.\n",
    "\n",
    "After classification, each data point classification embedding is compared to the original context to determine the similarity for that classification. _Note: We follow this approach rather than using the LLM, as LLMs are not well-suited for determining numeric similarity between text. Prompt the LLM to return a score would result in wild variations in the scores returned._\n",
    "\n",
    "#### Self-Classification\n",
    "\n",
    "For the self-classification scenario, the LLM is used to determine its own key observations/challenges associated with the data point provided. The criteria for determining classifications uses logic regarding common issues and opportunities to improve cloud products/services.\n",
    "\n",
    "#### Pre-Defined Classification\n",
    "\n",
    "For the pre-defined classification scenario, the `classifications` are used to narrow down the scope of the classification using the LLM. The output will be based on the most relevant matches to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp in filtered_data:\n",
    "    with Stopwatch() as sw:\n",
    "        prompt_tokens = 0\n",
    "        completion_tokens = 0    \n",
    "\n",
    "        dp_json = json.dumps({\n",
    "            \"attribution\": dp[\"attribution\"],\n",
    "            \"verbatim\": dp[\"verbatim\"]\n",
    "        }, cls=CustomEncoder)\n",
    "        \n",
    "        # 1 - Determine any facts from the data\n",
    "        context_content = context_prompt.format(context=dp_json, facts=\"To be determined\")\n",
    "        \n",
    "        planning_messages = [ChatCompletionUserMessageParam(role=\"user\", content=fact_prompt.format(task=self_classify_prompt, context=context_content))]\n",
    "        \n",
    "        fact_completion = openai_client.beta.chat.completions.parse(\n",
    "            model=env_vars[\"CHATCOMPLETION_DEPLOYMENTNAME\"],\n",
    "            messages=planning_messages,\n",
    "            response_format=RequestFactsModel,\n",
    "            temperature=0.3,\n",
    "            top_p=0.3\n",
    "        )\n",
    "        \n",
    "        facts = fact_completion.choices[0].message.parsed.model_dump()\n",
    "        prompt_tokens += fact_completion.usage.prompt_tokens\n",
    "        completion_tokens += fact_completion.usage.completion_tokens\n",
    "\n",
    "        context_content = context_prompt.format(context=dp_json, facts=facts)\n",
    "\n",
    "        if self_classify:\n",
    "            # 2 - Perform self-classification of the input data\n",
    "            execute_messages = [\n",
    "                ChatCompletionSystemMessageParam(role=\"system\", content=self_classify_prompt),\n",
    "                ChatCompletionUserMessageParam(role=\"user\", content=context_content)\n",
    "            ]\n",
    "\n",
    "            observation_completion = openai_client.beta.chat.completions.parse(\n",
    "                model=env_vars[\"CHATCOMPLETION_DEPLOYMENTNAME\"],\n",
    "                messages=execute_messages,\n",
    "                response_format=Observations,\n",
    "                temperature=0.3,\n",
    "                top_p=0.3\n",
    "            )\n",
    "        else:\n",
    "            # 2 - Classify the input data based on the provided classifications\n",
    "            classifications_json = [{\"classification\": c[\"classification\"], \"description\": c[\"description\"]} for c in classifications]\n",
    "            \n",
    "            execute_messages = [\n",
    "                ChatCompletionSystemMessageParam(role=\"system\", content=classify_prompt.format(classifications=json.dumps(classifications_json))),\n",
    "                ChatCompletionUserMessageParam(role=\"user\", content=context_content)\n",
    "            ]\n",
    "            \n",
    "            observation_completion = openai_client.beta.chat.completions.parse(\n",
    "                model=env_vars[\"CHATCOMPLETION_DEPLOYMENTNAME\"],\n",
    "                messages=execute_messages,\n",
    "                response_format=Observations,\n",
    "                temperature=0.3,\n",
    "                top_p=0.3\n",
    "            ) \n",
    "            \n",
    "        dp_observations = observation_completion.choices[0].message.parsed.model_dump()\n",
    "        prompt_tokens += observation_completion.usage.prompt_tokens\n",
    "        completion_tokens += observation_completion.usage.completion_tokens\n",
    "\n",
    "        # 3 - Get similarity score between the verbatim and the observations            \n",
    "        def process_observation(obs, dp_embedding):\n",
    "            if self_classify:\n",
    "                embedding = get_embedding(obs[\"short_name\"])\n",
    "            else:\n",
    "                embedding = next(c[\"embedding\"] for c in classifications if c[\"classification\"] == obs[\"short_name\"])\n",
    "            similarity = cosine_similarity([dp_embedding], [embedding])\n",
    "            obs[\"embedding\"] = embedding\n",
    "            obs[\"similarity\"] = round(similarity[0][0], 1)\n",
    "            return obs\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            dp_observations[\"observations\"] = list(\n",
    "                executor.map(lambda obs: process_observation(obs, dp[\"embedding\"]), dp_observations[\"observations\"])\n",
    "            )\n",
    "                    \n",
    "        execution_time = sw.get_current_elapsed()\n",
    "        \n",
    "        dp_observations[\"response_id\"] = dp[\"response_id\"]\n",
    "        dp_observations[\"execution_time\"] = execution_time\n",
    "        dp_observations[\"prompt_tokens\"] = prompt_tokens\n",
    "        dp_observations[\"completion_tokens\"] = completion_tokens\n",
    "        \n",
    "        all_dp_observations.append(dp_observations)\n",
    "        \n",
    "        create_json_file(os.path.join(classifications_output_dir, f\"{dp['response_id']}.json\"), dp_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_fpath = os.path.join(output_dir, \"output.csv\")\n",
    "\n",
    "output_data = []\n",
    "\n",
    "for dp in data:\n",
    "    dp_classifications = next(d for d in all_dp_observations if d[\"response_id\"] == dp[\"response_id\"])\n",
    "    dp_keywords = \", \".join([obs[\"short_name\"] for obs in dp_classifications[\"observations\"]])\n",
    "    dp_scores = \", \".join([f\"{obs['short_name']}: {obs['similarity']}\" for obs in dp_classifications[\"observations\"]])\n",
    "    \n",
    "    output_data.append([dp[\"response_id\"], dp[\"attribution\"], dp[\"verbatim\"], dp_keywords, dp_scores])\n",
    "    \n",
    "output_df = pd.DataFrame(output_data, columns=[\"ResponseId\", \"Attribution\", \"Verbatim\", \"Keyword\", \"Model Classification Scores\"])\n",
    "output_df.to_csv(output_csv_fpath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
