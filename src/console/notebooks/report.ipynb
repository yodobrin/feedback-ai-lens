{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report - focus on extracting insights\n",
    "\n",
    "Earlier we used the `classify.ipynb` notebook to load the feedbacks, load a classification file and using embedding perform classification on the data. In this notebook we will focus on extracting insights from the data. We will use LLM calls to summarize, identify key common themes or issues.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "A json file with the feedbacks and their classification, here is how it should look like:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"Id\": \"an id\",\n",
    "    \"PartnerShortName\": \"FastTrackFeedback\",\n",
    "    \"ServiceName\": \"Azure Data Factory - Data Movement\",\n",
    "    \"Type\": \"Feature Request\",\n",
    "    \"Title\": \"a title\",\n",
    "    \"Blocking\": \"\",\n",
    "    \"Description\": \"some description\",\n",
    "    \"WorkaroundAvailable\": \"No\",\n",
    "    \"Priority\": \"2\",\n",
    "    \"CustomerName\": \"Customer name\",\n",
    "    \"CustomerTpid\": \"\",\n",
    "    \"WorkaroundDescription\": \"some workaround \",\n",
    "    \"UserStory\": \"a user story\",\n",
    "    \"Embedding\": [\n",
    "    -0.010973175\n",
    "    ...\n",
    "    ],\n",
    "    \"ClassificationLevels\": [\n",
    "      \"Performance Efficiency\",\n",
    "      \"Data performance\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"Id\": \"FastTrackFeedback_396325\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "You will require LLM access. In this example, I am using Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.12\"\n",
    "#r \"nuget: DotNetEnv, 2.5.0\"\n",
    "// ability to load the entire console project, so no need to create local classes\n",
    "# r \"../bin/Debug/net8.0/console.dll\"\n",
    "\n",
    "using Azure; \n",
    "using Azure.AI.OpenAI;\n",
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "using System.Text.Json; \n",
    "using ProductLeaders.console.Models;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI\n",
    "\n",
    "As part of the report, there are calls to OpenAI to summarize the feedbacks. You will need to initialize OpenAI with your API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "static string _configurationFile = @\"../../../configuration/.env\";\n",
    "Env.Load(_configurationFile);\n",
    "\n",
    "string oAiApiKey = Environment.GetEnvironmentVariable(\"AOAI_APIKEY\") ?? \"AOAI_APIKEY not found\";\n",
    "string oAiEndpoint = Environment.GetEnvironmentVariable(\"AOAI_ENDPOINT\") ?? \"AOAI_ENDPOINT not found\";\n",
    "string chatCompletionDeploymentName = Environment.GetEnvironmentVariable(\"CHATCOMPLETION_DEPLOYMENTNAME\") ?? \"CHATCOMPLETION_DEPLOYMENTNAME not found\";\n",
    "string embeddingDeploymentName = Environment.GetEnvironmentVariable(\"EMBEDDING_DEPLOYMENTNAME\") ?? \"EMBEDDING_DEPLOYMENTNAME not found\";\n",
    "\n",
    "AzureKeyCredential azureKeyCredential = new AzureKeyCredential(oAiApiKey);\n",
    "OpenAIClient openAIClient = new OpenAIClient(new Uri(oAiEndpoint), azureKeyCredential);\n",
    "\n",
    "Console.WriteLine($\"OpenAI Client created: {oAiEndpoint} with: {chatCompletionDeploymentName} and {embeddingDeploymentName} deployments\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper method :: Call OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "async Task<string> CallOpenAI(string prompt, string systemMessage, bool JasonResponse = true)\n",
    "{\n",
    "    // Create ChatCompletionsOptions and set up the system and user messages\n",
    "    ChatCompletionsOptions options = new ChatCompletionsOptions();\n",
    "    \n",
    "    // Add system message\n",
    "    options.Messages.Add(new ChatRequestSystemMessage(systemMessage));\n",
    "    \n",
    "    // Add user message (the prompt generated from feedback)\n",
    "    options.Messages.Add(new ChatRequestUserMessage(prompt));\n",
    "\n",
    "    // Configure request properties\n",
    "    options.MaxTokens = 250;\n",
    "    options.Temperature = 0.7f;\n",
    "    options.NucleusSamplingFactor = 0.95f;\n",
    "    options.FrequencyPenalty = 0.0f;\n",
    "    options.PresencePenalty = 0.0f;\n",
    "    // options.StopSequences.Add(\"\\n\"); \n",
    "    options.DeploymentName = chatCompletionDeploymentName;\n",
    "    if (JasonResponse) options.ResponseFormat = ChatCompletionsResponseFormat.JsonObject;\n",
    "\n",
    "    // Make the API request to get the chat completions\n",
    "    // add timing for this call \n",
    "    var watch = System.Diagnostics.Stopwatch.StartNew();\n",
    "    Response<ChatCompletions> response = await openAIClient.GetChatCompletionsAsync(options);\n",
    "    watch.Stop();\n",
    "    var elapsedMs = watch.ElapsedMilliseconds;\n",
    "    Console.WriteLine($\"OpenAI API call took: {elapsedMs} ms\");\n",
    "\n",
    "    // Extract and return the first response from the choices\n",
    "    ChatCompletions completions = response.Value;\n",
    "    if (completions.Choices.Count > 0)\n",
    "    {\n",
    "        // Console.WriteLine($\"Response generated: {completions.Choices[0].Message.Content}\");\n",
    "        return completions.Choices[0].Message.Content;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        return \"No response generated.\";\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call\n",
    "\n",
    "When making the call to OpenAI, we instruct the LLM to perform the activities we wish to perform on it. This is where addtional insights might be required to be pulled out from the call, as of now, there is a specific `json` struct received from the LLM call. The struct needs to match the `LlmSummary` struct, thus making changes to the result from the LLM must be also addressed in the subsequent calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "const string CreateClusterSystemMessage = @\"\n",
    "You are a helpful assistant. When responding, follow these rules:\n",
    "1. Output only valid JSON. Do not include any markdown, quotes, or extra text.\n",
    "2. The JSON must have this structure:\n",
    "{\n",
    "  \"\"CommonElement\"\": \"\"<A concise phrase describing the common theme>\"\",\n",
    "  \"\"Summary\"\": \"\"<A detailed explanation summarizing the feedback>\"\"\n",
    "}\n",
    "3. Base your summary solely on the provided user stories.\n",
    "4. If any user story is unrelated, you may still incorporate it in the summary if there's a consistent theme.\n",
    "\";\n",
    "\n",
    "public class LlmSummary\n",
    "{\n",
    "    public string CommonElement { get; set; }\n",
    "    public string Summary { get; set; }\n",
    "}\n",
    "\n",
    "string BuildUserPrompt(IEnumerable<string> userStories, string pillarName, string subCatName)\n",
    "{\n",
    "    // You might add some context about the subcategory:\n",
    "    var sb = new StringBuilder();\n",
    "    sb.AppendLine($\"Pillar: {pillarName}\");\n",
    "    sb.AppendLine($\"Subcategory: {subCatName}\");\n",
    "    sb.AppendLine(\"Here are user stories:\");\n",
    "    foreach (var story in userStories)\n",
    "    {\n",
    "        sb.AppendLine($\"- {story}\");\n",
    "    }\n",
    "    sb.AppendLine();\n",
    "    sb.AppendLine(\"Generate the JSON based on these stories:\");\n",
    "    return sb.ToString();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.Text.Json;\n",
    "\n",
    "public async Task<Dictionary<string, LlmSummary>> GenerateStructuredInsightsAsync(\n",
    "    List<ProductLeaders.console.Models.FeedbackRecord> feedbackRecords)\n",
    "{\n",
    "    // We'll store \"pillar::subCat\" -> LlmSummary\n",
    "    // but in your new approach, \"pillar\" and \"subCat\" come from ClassificationLevels\n",
    "    var insightsDictionary = new Dictionary<string, LlmSummary>();\n",
    "\n",
    "    // Group by the first two classification levels, e.g. [0] => Pillar, [1] => SubCat\n",
    "    // If a record has only 1 level, treat subCat as \"(None)\".\n",
    "    var grouped = feedbackRecords\n",
    "        .Where(f => f.ClassificationLevels != null && f.ClassificationLevels.Count > 0)\n",
    "        .GroupBy(f =>\n",
    "        {\n",
    "            // classificationLevels[0] => Pillar\n",
    "            var level1 = f.ClassificationLevels[0];\n",
    "            // classificationLevels[1] => SubCat (if it exists, otherwise \"(None)\")\n",
    "            var level2 = f.ClassificationLevels.Count >= 2\n",
    "                ? f.ClassificationLevels[1]\n",
    "                : \"(None)\";\n",
    "            return new { Pillar = level1, SubCat = level2 };\n",
    "        })\n",
    "        // Order pillars, then subcats\n",
    "        .OrderBy(g => g.Key.Pillar)\n",
    "        .ThenBy(g => g.Key.SubCat);\n",
    "\n",
    "    // For each group, gather user stories & decide whether to call the LLM\n",
    "    foreach (var group in grouped)\n",
    "    {\n",
    "        var pillarName = group.Key.Pillar;\n",
    "        var subCatName = group.Key.SubCat;\n",
    "        var count = group.Count();\n",
    "\n",
    "        // We'll use \"pillarName::subCatName\" as the dictionary key\n",
    "        string dictKey = $\"{pillarName}::{subCatName}\";\n",
    "\n",
    "        // Only call LLM if > 5\n",
    "        if (count > 5)\n",
    "        {\n",
    "            // Possibly sample to 20 items\n",
    "            var itemSamples = group.Take(20).ToList();\n",
    "            // Gather user stories\n",
    "            var userStoryTexts = itemSamples.Select(f => f.UserStory);\n",
    "\n",
    "            // Call the LLM to get structured summary\n",
    "            LlmSummary summaryObj = await GetStructuredSummaryAsync(userStoryTexts, pillarName, subCatName);\n",
    "\n",
    "            insightsDictionary[dictKey] = summaryObj;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            // fewer than 6 items => no summary\n",
    "            insightsDictionary[dictKey] = null;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return insightsDictionary;\n",
    "}\n",
    "\n",
    "// ---------------------------------------------------------------------\n",
    "// Helper method that calls the LLM and returns an LlmSummary from JSON.\n",
    "// This merges logic from your first snippet (GetStructuredSummaryAsync).\n",
    "// ---------------------------------------------------------------------\n",
    "private async Task<LlmSummary> GetStructuredSummaryAsync(\n",
    "    IEnumerable<string> userStories,\n",
    "    string level1,\n",
    "    string level2)\n",
    "{\n",
    "    // 1) Build user message for LLM (prompt)\n",
    "    string userPrompt = BuildUserPrompt(userStories, level1, level2);\n",
    "\n",
    "    // 2) Make the LLM call\n",
    "    Console.WriteLine($\"Generating summary for {level1} - {level2} ({userStories.Count()} items)...\");\n",
    "    string rawResponse = await CallOpenAI(userPrompt, CreateClusterSystemMessage, true);\n",
    "\n",
    "    // 3) Attempt to parse the JSON\n",
    "    try\n",
    "    {\n",
    "        var summary = JsonSerializer.Deserialize<LlmSummary>(rawResponse);\n",
    "        if (summary == null)\n",
    "        {\n",
    "            return new LlmSummary\n",
    "            {\n",
    "                CommonElement = \"ParsingError\",\n",
    "                Summary = \"LLM returned null or invalid JSON\"\n",
    "            };\n",
    "        }\n",
    "        Console.WriteLine($\"Summary generated: {summary.Summary}\");\n",
    "        return summary;\n",
    "    }\n",
    "    catch (JsonException ex)\n",
    "    {\n",
    "        // handle malformed JSON\n",
    "        return new LlmSummary\n",
    "        {\n",
    "            CommonElement = \"ParsingError\",\n",
    "            Summary = $\"Failed to parse LLM output as JSON. Error: {ex.Message}\"\n",
    "        };\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown Report\n",
    "\n",
    "The last step is to create a readable report in markdown format. The report will contain few aggregated statistics, insights per group of feedbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.Text;\n",
    "using System.Linq;\n",
    "\n",
    "\n",
    "\n",
    "public class MarkdownBuilder\n",
    "{\n",
    "    // Provide a method that builds the Markdown with:\n",
    "    //  - A summary table of subcategories in each pillar\n",
    "    //  - Detailed listing with optional LLM summaries\n",
    "    public string BuildMarkdown(\n",
    "        Dictionary<string, LlmSummary> summaries,\n",
    "        Dictionary<string, List<ProductLeaders.console.Models.FeedbackRecord>> feedbacks)\n",
    "    {\n",
    "        var sb = new StringBuilder();\n",
    "        sb.AppendLine(\"# WAF Feedback Report\");\n",
    "        sb.AppendLine();\n",
    "\n",
    "        // -------------------------------------------------\n",
    "        // 1) Group by pillar (top-level).\n",
    "        // Key in feedbacks is \"Pillar::Subcat\"\n",
    "        // We'll produce data structures for each pillar\n",
    "        // plus a top-level summary table of pillars.\n",
    "        // -------------------------------------------------\n",
    "        var groupedByPillar = feedbacks\n",
    "            .GroupBy(kv => kv.Key.Split(\"::\", 2)[0]) // pillar = everything before \"::\"\n",
    "            .Select(g => new\n",
    "            {\n",
    "                PillarName = g.Key,\n",
    "                // Dictionary of subcatKey -> List<FeedbackRecord>\n",
    "                SubcatDictionary = g.ToDictionary(x => x.Key, x => x.Value)\n",
    "            })\n",
    "            // Sort pillars by total feedback count desc\n",
    "            .OrderByDescending(p => p.SubcatDictionary.Values.Sum(list => list.Count))\n",
    "            .ToList();\n",
    "\n",
    "        // 1A) Build a top-level table showing each pillar + total count\n",
    "        sb.AppendLine(\"## Summary of All Pillars\");\n",
    "        sb.AppendLine();\n",
    "        sb.AppendLine(\"| Pillar | Total Feedback Count |\");\n",
    "        sb.AppendLine(\"|--------|-----------------------|\");\n",
    "\n",
    "        foreach (var pillarGroup in groupedByPillar)\n",
    "        {\n",
    "            // Sum the subcategory counts to get total for pillar\n",
    "            int totalCount = pillarGroup.SubcatDictionary.Values.Sum(list => list.Count);\n",
    "            sb.AppendLine($\"| {EscapeMd(pillarGroup.PillarName)} | {totalCount} |\");\n",
    "        }\n",
    "\n",
    "        sb.AppendLine();\n",
    "\n",
    "        // -------------------------------------------------\n",
    "        // 2) Now, for each pillar, show details:\n",
    "        //    - A subcategory summary table\n",
    "        //    - The subcategories themselves with optional LLM summary\n",
    "        // -------------------------------------------------\n",
    "        foreach (var pillarGroup in groupedByPillar)\n",
    "        {\n",
    "            int pillarCount = pillarGroup.SubcatDictionary.Values.Sum(list => list.Count);\n",
    "\n",
    "            sb.AppendLine($\"## {pillarGroup.PillarName} (Total: {pillarCount})\");\n",
    "            sb.AppendLine();\n",
    "\n",
    "            // 2A) Build a subcategory summary table\n",
    "            sb.AppendLine(\"| Subcategory | Feedback Count |\");\n",
    "            sb.AppendLine(\"|-------------|----------------|\");\n",
    "\n",
    "            // Order subcategories by count desc\n",
    "            var subCatEntries = pillarGroup.SubcatDictionary\n",
    "                .OrderByDescending(sc => sc.Value.Count)\n",
    "                .ToList();\n",
    "\n",
    "            foreach (var subCatEntry in subCatEntries)\n",
    "            {\n",
    "                string key = subCatEntry.Key; // e.g. \"Reliability::Scaling\"\n",
    "                var subcatRecords = subCatEntry.Value;\n",
    "                int subcatCount = subcatRecords.Count;\n",
    "\n",
    "                // subcat name is after \"::\"\n",
    "                var parts = key.Split(\"::\", 2);\n",
    "                string subCatName = parts.Length > 1 ? parts[1] : \"(None)\";\n",
    "\n",
    "                sb.AppendLine($\"| {EscapeMd(subCatName)} | {subcatCount} |\");\n",
    "            }\n",
    "            sb.AppendLine();\n",
    "\n",
    "            // 2B) Detailed listing for each subcategory\n",
    "            foreach (var subCatEntry in subCatEntries)\n",
    "            {\n",
    "                string key = subCatEntry.Key;\n",
    "                var subcatRecords = subCatEntry.Value;\n",
    "                int subcatCount = subcatRecords.Count;\n",
    "\n",
    "                var parts = key.Split(\"::\", 2);\n",
    "                string subCatName = parts.Length > 1 ? parts[1] : \"(None)\";\n",
    "\n",
    "                sb.AppendLine($\"### {subCatName} (Count: {subcatCount})\");\n",
    "                sb.AppendLine();\n",
    "\n",
    "                // Check for LLM summary\n",
    "                if (summaries.TryGetValue(key, out var llmSummary) && llmSummary != null)\n",
    "                {\n",
    "                    sb.AppendLine(\"**LLM Summary**:\");\n",
    "                    sb.AppendLine();\n",
    "                    sb.AppendLine($\"- **CommonElement**: {EscapeMd(llmSummary.CommonElement ?? \"\")}\");\n",
    "                    sb.AppendLine($\"- **Summary**: {EscapeMd(llmSummary.Summary ?? \"\")}\");\n",
    "                    sb.AppendLine();\n",
    "                }\n",
    "                else\n",
    "                {\n",
    "                    sb.AppendLine(\"> No summary was generated (≤ 5 feedback items or not processed).\");\n",
    "                    sb.AppendLine();\n",
    "                }\n",
    "\n",
    "                // // 2C) Collapsible details for each item\n",
    "                // foreach (var record in subcatRecords)\n",
    "                // {\n",
    "                //     sb.AppendLine(\"<details>\");\n",
    "                //     sb.AppendLine($\"<summary>{EscapeHtml(record.Title ?? \"No Title\")}</summary>\");\n",
    "                //     sb.AppendLine();\n",
    "                //     sb.AppendLine($\"**ID**: {EscapeHtml(record.Id ?? \"\")}\");\n",
    "                //     sb.AppendLine();\n",
    "                //     sb.AppendLine($\"**User Story**: {EscapeHtml(record.UserStory ?? \"\")}\");\n",
    "                //     sb.AppendLine();\n",
    "                //     sb.AppendLine(\"</details>\");\n",
    "                //     sb.AppendLine();\n",
    "                // }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return sb.ToString();\n",
    "    }\n",
    "    // Minimal escaping for the subcat name (in table cells).\n",
    "    private string EscapeMd(string text)\n",
    "    {\n",
    "        if (string.IsNullOrEmpty(text)) return \"\";\n",
    "        // Escape | in table cells\n",
    "        return text.Replace(\"|\", \"\\\\|\");\n",
    "    }\n",
    "\n",
    "    // Minimal HTML escaping for <details> content\n",
    "    private string EscapeHtml(string input)\n",
    "    {\n",
    "        if (string.IsNullOrEmpty(input)) return \"\";\n",
    "        return input\n",
    "            .Replace(\"&\", \"&amp;\")\n",
    "            .Replace(\"<\", \"&lt;\")\n",
    "            .Replace(\">\", \"&gt;\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching each classification\n",
    "\n",
    "Now we will be able to call LLM with specific set of items to summarize or perform any insight extraction. the outcome is saved to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// 1) Load the feedback\n",
    "var feedbackList = JsonSerializer.Deserialize<List<ProductLeaders.console.Models.FeedbackRecord>>(File.ReadAllText(\"feedback_classified.json\"));\n",
    "Console.WriteLine($\"Loaded {feedbackList.Count} feedback records.\");\n",
    "// var insights = await GenerateStructuredInsightsAsync(feedbackList);\n",
    "\n",
    "// 2) Generate or load your insights\n",
    "// Option A: Call the LLM now\n",
    "var insightsDict = await GenerateStructuredInsightsAsync(feedbackList);\n",
    "\n",
    "var json = JsonSerializer.Serialize(insightsDict);\n",
    "File.WriteAllText(\"pillar_subcat_insights.json\", json);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the report\n",
    "\n",
    "The report builder requires the feedbacks and the enriched classification (two distinct files), while the feedback list is a non sorted items, the report builder expect a grouped feedbacks, therefore in the next step we will group the feedbacks by classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// 1) Load the LLM insights (Dictionary<string, LlmSummary>)\n",
    "string insightsFile = \"pillar_subcat_insights.json\";\n",
    "Dictionary<string, LlmSummary> insights =\n",
    "    JsonSerializer.Deserialize<Dictionary<string, LlmSummary>>(File.ReadAllText(insightsFile));\n",
    "\n",
    "// 2) Load the classified feedback (List<FeedbackRecord>)\n",
    "string feedbackFile = \"feedback_classified.json\";\n",
    "var feedbackList =\n",
    "    JsonSerializer.Deserialize<List<ProductLeaders.console.Models.FeedbackRecord>>(File.ReadAllText(feedbackFile));\n",
    "\n",
    "if (insights == null || feedbackList == null)\n",
    "{\n",
    "    Console.WriteLine(\"Failed to load insights or feedback data.\");\n",
    "    return;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// 3) Group feedback: \"pillar::subcat\" => List<FeedbackRecord> in this case there are only 2 levels\n",
    "var feedbackByPillarSubcat = feedbackList\n",
    "    .Where(f => f.ClassificationLevels != null && f.ClassificationLevels.Count > 0)\n",
    "    .GroupBy(f =>\n",
    "    {\n",
    "        string level1 = f.ClassificationLevels[0];\n",
    "        // if there's a second level, use it; otherwise \"(None)\"\n",
    "        string level2 = (f.ClassificationLevels.Count > 1)\n",
    "            ? f.ClassificationLevels[1]\n",
    "            : \"(None)\";\n",
    "        return $\"{level1}::{level2}\";\n",
    "    })\n",
    "    .ToDictionary(g => g.Key, g => g.ToList());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the report builder\n",
    "\n",
    "We now have the required artifacts to call the report builder. The report builder will generate a markdown file with the insights extracted from the feedbacks. The section which prints the actual feedbacks is commented out, as it might be too verbose, however it is available to report on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var builder = new MarkdownBuilder();\n",
    "string mdContent = builder.BuildMarkdown(insights, feedbackByPillarSubcat);\n",
    "\n",
    "File.WriteAllText(\"waf_report.md\", mdContent);\n",
    "Console.WriteLine(\"Report generated: waf_report.md\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
